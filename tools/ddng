#! /usr/bin/env -S deno run --ext=ts --allow-read --allow-write --allow-env --allow-net --allow-run --allow-sys
// Copyright Deno Land Inc. All Rights Reserved. Proprietary and confidential.

import { parseArgs } from "jsr:@std/cli@1.0.3/parse-args";
import { join } from "jsr:@std/path@1.0.3/join";
import { ensureDir } from "jsr:@std/fs@1.0.3";
import { crypto } from "jsr:@std/crypto@1.0.3";
import { encodeBase64Url } from "jsr:@std/encoding@1.0.7";
import { retry, RetryError } from "jsr:@std/async/retry";

interface DeployArgs {
  clusterEndpoint: URL;
  clusterHostname: string;
  apiEndpoint: URL;
  domain?: string;
  sourceDir?: string;
  entryPoint?: string;
  env?: Record<string, string>;
  authKey?: string;
  authClaims?: string;
  skipOptimization?: boolean;
  ext2?: boolean;
  squashfs?: boolean;
  disableGvisor?: boolean;
  otelServiceName?: string;
  otelServiceVersion?: string;
  otelResourceAttributes?: Record<string, string>;
}

export interface UserConfig {
  code?: string;
  entrypoint?: string;
  env?: Record<string, string>;
  args?: string[];
  otel?: OtelConfig;
  cache?: Record<string, CacheConfig>;
  pool?: string;
}

interface OtelConfig {
  serviceName?: string;
  serviceVersion?: string;
  resourceAttributes?: Record<string, string>;
}

interface CacheConfig {
  private: Record<string, string>;
  shared?: Record<string, string>;
  tags: Record<string, string>;
}

type BucketPayload = string | { path: string };

const client = Deno.createHttpClient({ allowHost: true, http2: false });

// Return a function for writing content into the storage bucket.
function createWriter(
  authToken: string | undefined,
  args: Pick<DeployArgs, "apiEndpoint" | "clusterEndpoint">,
) {
  const headers: Record<string, string> = authToken
    ? {
      "x-deno-authorization": `Bearer ${authToken}`,
    }
    : {};
  headers["host"] = args.apiEndpoint.hostname;

  // Write the provided file or string into the given path. Returns
  // the full URL of the created object on success or false.
  return async function write(
    path: string,
    payload: BucketPayload,
  ): Promise<boolean> {
    let body;
    if (typeof payload === "string") {
      body = payload;
    } else {
      try {
        // TODO: stream the content once the server can accept request with no Content-Length.
        body = await Deno.readFile(payload.path);
      } catch (e) {
        console.error(`Could not open ${payload.path}: ${e}`);
        return false;
      }
    }

    const fmt = (n: number) => n.toFixed(2);
    const sz = body.length >= 1024 * 1024
      ? `${fmt(body.length / 1024 / 1024)}MB`
      : body.length >= 1024
        ? `${fmt(body.length / 1024)}KB`
        : `${body.length} bytes`;

    const url = new URL(args.clusterEndpoint);
    url.pathname = path;
    const doit = async () => {
      console.info(`Putting '${path}' in the bucket (${sz})...`);

      const response = await fetch(
        url,
        { method: "PUT", headers, body, client },
      );

      if (!response.ok) {
        const text = await response.text();
        console.error(
          `Failed to upload content (status=${response.status}): ${text} `,
        );
        throw new Error();
      }

      return response;
    };

    try {
      const res = await retry(doit, { maxAttempts: 3, maxTimeout: 10_000 });
      return res.ok;
    } catch (e) {
      console.error(
        `Operation failed after 3 retries. Error: ${Deno.inspect(e)}`,
      );
      return false;
    }
  };
}

async function createJwtToken(
  args: Pick<DeployArgs, "authKey" | "authClaims" | "clusterHostname">,
): Promise<string | undefined> {
  if (!args.authKey) return;

  const keyContent = await Deno.readTextFile(args.authKey);
  const base64 = keyContent.replace(/(-{5}[^\\n]+-{5}|\s+)/g, "");
  const buf = Uint8Array.from(atob(base64), (ch) => ch.charCodeAt(0));

  let key;
  try {
    key = await crypto.subtle.importKey(
      "pkcs8",
      buf,
      { name: "ECDSA", namedCurve: "P-256" },
      false,
      ["sign"],
    );
  } catch (e) {
    console.error("Could not load JWT signing key from the pem file");
    console.error(e);
    Deno.exit(1);
  }

  let claimsOverride;
  try {
    claimsOverride = args.authClaims ? JSON.parse(args.authClaims) : {};
  } catch (e) {
    console.error("--auth-claims must be a valid json.");
    console.error(e);
    Deno.exit(1);
  }

  const header = encodeBase64Url(JSON.stringify({
    typ: "JWT",
    alg: "ES256",
  }));

  const claims = encodeBase64Url(JSON.stringify({
    iss: "local",
    aud: args.clusterHostname,
    sub: "admin",
    exp: Math.trunc(Date.now() / 1000) + 600,
    scope: "appconfig bucket:w",
    ...claimsOverride,
  }));

  const message = `${header}.${claims}`;
  const dataToSign = new TextEncoder().encode(message);
  const signature = encodeBase64Url(
    await crypto.subtle.sign(
      { name: "ECDSA", hash: "sha-256" },
      key,
      dataToSign,
    ),
  );

  return `${message}.${signature}`;
}

async function deploy(args: DeployArgs) {
  // Validate required parameters
  if (!args.domain) {
    console.error("Deployment domain is required.");
    usage();
    Deno.exit(1);
  }

  const authToken = await createJwtToken(args);
  const writeToBucket = createWriter(authToken, args);

  const sourceDir = args.sourceDir || Deno.cwd();
  let entryPoint = args.entryPoint;

  // Prepare temp directory
  const tempDir = await Deno.makeTempDir({ prefix: "deno-cluster" });

  try {
    await ensureDir(join(tempDir, "pkg", "deno_dir"));
    await ensureDir(join(tempDir, "pkg", "src"));

    // Copy source code to tempdir
    const copyCommand = new Deno.Command("bash", {
      args: [
        "-c",
        `(cd "${sourceDir}" && tar --exclude='.git' -cf - .) | (cd "${tempDir}/pkg/src" && tar -xf -)`,
      ],
      stdout: "inherit",
      stderr: "inherit",
    });
    const { success: copySuccess } = await copyCommand
      .output();
    if (!copySuccess) {
      console.error("Failed to copy source code.");
      Deno.exit(1);
    }

    // Detect entry point if not specified
    if (!entryPoint) {
      const possibleEntryPoints = [
        "main.ts",
        "main.js",
        "index.ts",
        "index.js",
        "mod.ts",
        "mod.js",
        "node_modules/.bin/next",
      ];
      for (const ep of possibleEntryPoints) {
        if (
          await Deno.stat(join(tempDir, "pkg", "src", ep)).catch(() => null)
        ) {
          entryPoint = ep;
          break;
        }
      }
    }

    if (!entryPoint) {
      console.error("Error: could not determine entry point.");
      Deno.exit(1);
    }

    const isNextApp = entryPoint === "node_modules/.bin/next";

    console.log(`  entry point: ${entryPoint}`);

    console.log("Building package...");

    // Cache dependencies
    const cacheCommand = new Deno.Command("deno", {
      env: { "DENO_DIR": join(tempDir, "pkg", "deno_dir") },
      args: [
        "install",
        "--allow-import",
        "--entrypoint",
        join(tempDir, "pkg", "src", entryPoint),
      ],
      stdout: "inherit",
      stderr: "inherit",
      cwd: join(tempDir, "pkg", "src"),
    });
    const { success: cacheSuccess } = await cacheCommand
      .output();
    if (!cacheSuccess) {
      console.error("Failed to cache dependencies.");
      Deno.exit(1);
    }

    let localCodePath: string;
    let remoteCodePath: string;

    let numFsOptions = 0;
    if (args.ext2) numFsOptions++;
    if (args.squashfs) numFsOptions++;
    if (numFsOptions > 1) {
      console.error("Only one of --ext2 or --squashfs can be specified.");
      Deno.exit(1);
    }

    // Create ext2/squashfs image or tar archive
    if (args.ext2) {
      localCodePath = join(tempDir, "pkg.ext2.img");
      remoteCodePath = `images/pkg-${Date.now()}-${crypto.randomUUID()}.ext2.img`;

      const duCommand = new Deno.Command("du", {
        args: [
          "-sm",
          join(tempDir, "pkg"),
        ],
        stdout: "piped",
        stderr: "inherit",
      });
      const duOutput = await duCommand.output();
      if (!duOutput.success) {
        console.error("Failed to calculate package size.");
        Deno.exit(1);
      }
      const pkgSizeMB = parseInt(new TextDecoder().decode(duOutput.stdout).split("\t")[0]);

      // count the number of files
      const findCommand = new Deno.Command("find", {
        args: [
          join(tempDir, "pkg"),
          "-type",
          "f",
        ],
        stdout: "piped",
        stderr: "inherit",
      });
      const findOutput = await findCommand.output();
      if (!findOutput.success) {
        console.error("Failed to count files in package.");
        Deno.exit(1);
      }
      const fileCount = new TextDecoder().decode(findOutput.stdout).split("\n").length - 1;

      const blockSize = 4096;
      const fsSizeMB = Math.floor(pkgSizeMB + fileCount * blockSize / 1048576 + 2);

      const mkfsCommand = new Deno.Command("mke2fs", {
        args: [
          "-L",
          "",
          "-b",
          `${blockSize}`,
          "-d",
          join(tempDir, "pkg"),
          "-t",
          "ext2",
          localCodePath,
          `${fsSizeMB}M`,
        ],
        stdout: "inherit",
        stderr: "inherit",
      });
      const { success: mkfsSuccess } = await mkfsCommand
        .output();
      if (!mkfsSuccess) {
        console.error("Failed to create ext2 disk image.");
        Deno.exit(1);
      }

      console.log("Fixing up permissions...")
      let totalFiles = 0;
      let totalDirs = 0;
      let stack = ["/"];
      while (stack.length) {
        // the `ext2fs` package has a memory leak in its Emscripten-compiled WASM so we have to reset it every 1000 files
        const worker = new Worker(new URL("fix_permissions.ts", import.meta.url).href, { type: "module", deno: {} });
        worker.postMessage({ localCodePath, stack })
        const timeoutId = setTimeout(() => {
          console.error("Worker time out, current stack:", stack);
          Deno.exit(1);
        }, 10000);
        const { data }: { data: { stack: string[], totalFiles: number, totalDirs: number } } = await new Promise((resolve, reject) => { worker.onmessage = resolve; worker.onerror = reject; });
        clearTimeout(timeoutId);
        stack = data.stack;
        totalFiles += data.totalFiles;
        totalDirs += data.totalDirs;
      }
      console.log(`Fixed permissions on ${totalFiles} files and ${totalDirs} directories.`);
    } else if (args.squashfs) {
      localCodePath = join(tempDir, "pkg.squashfs.img");
      remoteCodePath = `images/pkg-${Date.now()}-${crypto.randomUUID()}.squashfs.img`;

      const mkfsCommand = new Deno.Command("mksquashfs", {
        args: [
          join(tempDir, "pkg"),
          localCodePath,
          "-force-uid",
          "1",
          "-force-gid",
          "1",
        ],
        stdout: "inherit",
        stderr: "inherit",
      });
      const { success: mkfsSuccess } = await mkfsCommand
        .output();
      if (!mkfsSuccess) {
        console.error("Failed to create squashfs disk image.");
        Deno.exit(1);
      }
    } else {
      localCodePath = join(tempDir, "pkg.tar");
      remoteCodePath = `code/pkg-${Date.now()}-${crypto.randomUUID()}.tar`;
      const tarCommand = new Deno.Command("tar", {
        args: [
          "cf",
          localCodePath,
          "--strip-components=1",
          "-C",
          join(tempDir, "pkg"),
          ".",
        ],
        stdout: "inherit",
        stderr: "inherit",
      });
      const { success: tarSuccess } = await tarCommand
        .output();
      if (!tarSuccess) {
        console.error("Failed to create tar archive.");
        Deno.exit(1);
      }
    }

    // Upload package
    console.log("Uploading package...");
    if (
      !await writeToBucket(remoteCodePath, {
        path: localCodePath,
      })
    ) {
      console.error("Failed to upload package.");
      Deno.exit(1);
    }

    console.log(`Uploaded code to /${remoteCodePath}`);

    // Construct the config object.
    const cacheAttrs = { org: "placeholder", random: crypto.randomUUID() };
    const appconfigJson = JSON.stringify(
      <UserConfig>{
        code: "/" + remoteCodePath,
        entrypoint: entryPoint,
        args: isNextApp ? ["start"] : undefined,
        env: Object.keys(args.env || {}).length > 0 ? args.env : undefined,
        otel: (args.otelServiceName || args.otelServiceVersion ||
          args.otelResourceAttributes)
          ? {
            serviceName: args.otelServiceName,
            serviceVersion: args.otelServiceVersion,
            resourceAttributes: args.otelResourceAttributes,
          }
          : undefined,
        cache: {
          "*": {
            private: { ...cacheAttrs },
            tags: {},
          },
          "http": {
            private: {
              ...cacheAttrs,
              subspace: "http",
            },
            tags: {},
          },
        },
        experimental: args.disableGvisor ? { disableGvisor: true } : undefined,
      },
    );

    // Make a HTTP request to the cluster to trigger deployment
    if (!(args.skipOptimization ?? false)) {
      console.log("Optimizing deployment...");
      const headers: Record<string, string> = authToken
        ? {
          "x-deno-authorization": `Bearer ${authToken}`,
        }
        : {};
      headers["x-deno-appconfig"] = appconfigJson;
      headers["host"] = args.domain;

      try {
        const response = await fetch(
          args.clusterEndpoint,
          { headers, client },
        );

        // Proxy always sends back a `via` header before it starts proxying the
        // response from an isolate.
        //
        // Checking the request status is not reliable here if the user script
        // returns a non-200 response. In that case the optimization has still
        // been successful.
        if (!response.headers.has("via")) {
          throw new Error(
            `Failed to optimize deployment: ${response.status}`,
          );
        }
      } catch (e) {
        console.error("Failed to optimize deployment");
        throw e;
      }
    } else {
      console.log("Skipping optimization step...");
    }

    // Update domain mapping
    console.log(`Attaching ${args.domain}...`);
    if (
      !await writeToBucket(
        `domains/${args.domain}`,
        appconfigJson,
      )
    ) {
      console.error("Failed to attach domain.");
      Deno.exit(1);
    }

    console.log(`Deployed to https://${args.domain}`);
  } finally {
    // Clean up temp directory
    await Deno.remove(tempDir, { recursive: true });
  }
}

function usage() {
  console.log("Usage: cli.ts <command> [options]");
  console.log("Commands:");
  console.log("  deploy                         Create a new deployment");
  console.log();
  console.log("Options:");
  console.log(
    "  -d,--domain <domain>             Deployment domain (e.g., hello.mycluster.deno-cluster.net)",
  );
  console.log(
    "  -s,--source-dir <dir>            Source directory (default: current directory)",
  );
  console.log(
    "  -e,--entry-point <file>          Specify entry point (default: auto detect)",
  );
  console.log(
    "  -k,--key <file>                  The private key to use for the JWT authorization",
  );
  console.log(
    "  --env <KEY=VALUE>                Set environment variables using KEY=VALUE format, can be specified multiple times",
  );
  console.log(
    "  --api-endpoint                   Specify cluster objects api endpoint (defaults to `objects.api.{cluster-endpoint}`)",
  );
  console.log(
    "  --otel-service-name <name>       Specify OpenTelemetry service name",
  );
  console.log(
    "  --otel-service-version <ver>     Specify OpenTelemetry service version",
  );
  console.log(
    "  --otel-resource-attribute <K=V>  Specify OpenTelemetry resource attributes in KEY=VALUE format, can be specified multiple times",
  );
  console.log(
    "  --auth-claims <json>             Overrides the default values for the authorization claims",
  );
  console.log(
    "  --skip-optimize                  Skip the optimization step",
  );
  console.log(
    "  --ext2                           Build ext2 disk image instead of tarball",
  );
  console.log(
    "  --squashfs                       Build squashfs disk image instead of tarball",
  );
  console.log(
    "  --disable-gvisor                 Disable gVisor for this deployment",
  );
  Deno.exit(1);
}

if (import.meta.main) {
  if (+Deno.version.deno.replace(/\..*$/, "") < 2) {
    console.error("This program requires deno version 2.0.0 or higher");
    Deno.exit(1);
  }

  const args = parseArgs(Deno.args, {
    string: [
      "domain",
      "source-dir",
      "entry-point",
      "env",
      "otel-service-name",
      "otel-service-version",
      "otel-resource-attribute",
      "api-endpoint",
      "key",
      "auth-claims",
    ],
    collect: ["env", "otel-resource-attribute"],
    alias: {
      d: "domain",
      s: "source-dir",
      e: "entry-point",
      k: "key",
    },
    boolean: ["skip-optimize", "ext2", "squashfs", "disable-gvisor"],
  });

  if (args._[0] === "deploy") {
    const clusterEndpoint = new URL(
      Deno.env.get("CLUSTER_ENDPOINT") ?? "http://localhost:4080",
    );
    const clusterHostname = Deno.env.get("CLUSTER_HOSTNAME") ??
      (clusterEndpoint.hostname.match(/[a-z]/i)
        ? clusterEndpoint.hostname
        : "localhost");
    const apiEndpoint = new URL(
      args["api-endpoint"] ||
      `${clusterEndpoint.protocol}//objects.api.${clusterHostname}`,
    );
    clusterEndpoint.pathname = "";

    await deploy({
      domain: args.domain,
      sourceDir: args["source-dir"],
      entryPoint: args["entry-point"],
      env: args.env.length > 0
        ? Object.fromEntries(args.env.map((e: string) => {
          const eqIndex = e.indexOf("=");
          if (eqIndex === -1) {
            console.error(`Invalid environment variable: ${e}`);
            Deno.exit(1);
          }
          return [e.slice(0, eqIndex), e.slice(eqIndex + 1)];
        }))
        : undefined,
      authKey: args["key"],
      authClaims: args["auth-claims"],
      skipOptimization: args["skip-optimize"],
      ext2: args["ext2"],
      squashfs: args["squashfs"],
      disableGvisor: args["disable-gvisor"],
      otelServiceName: args["otel-service-name"],
      otelServiceVersion: args["otel-service-version"],
      otelResourceAttributes: args["otel-resource-attribute"].length > 0
        ? Object.fromEntries(
          args["otel-resource-attribute"].map((attr: string) => {
            const eqIndex = attr.indexOf("=");
            if (eqIndex === -1) {
              console.error(`Invalid resource attribute: ${attr}`);
              Deno.exit(1);
            }
            return [attr.slice(0, eqIndex), attr.slice(eqIndex + 1)];
          }),
        )
        : undefined,
      clusterEndpoint,
      clusterHostname,
      apiEndpoint,
    });
  } else if (args._[0] === "help" || args.help) {
    usage();
  } else {
    console.error("Unknown command");
    Deno.exit(1);
  }
}
